{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "device = \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 120, 120])\n",
      "torch.Size([1, 16, 57, 57])\n",
      "torch.Size([1, 3, 58, 58])\n"
     ]
    }
   ],
   "source": [
    "# preprocessing\n",
    "\n",
    "# loading image\n",
    "image = Image.open('1.jpg')\n",
    "image = image.resize((120,120))\n",
    "\n",
    "#image.show()\n",
    "\n",
    "trans = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((120,120)),\n",
    "    transforms.Normalize(0.5,0.5,0.5)\n",
    "])\n",
    "\n",
    "image = trans(image)\n",
    "print(image.shape)\n",
    "image = image.view(1,3,120,120)\n",
    "\n",
    "maxp = torch.nn.MaxPool2d(2,2)\n",
    "convex = torch.nn.Conv2d(3, 8, kernel_size=3)\n",
    "convex1 = torch.nn.Conv2d(8, 16, kernel_size=3)\n",
    "\n",
    "batch1 = torch.nn.BatchNorm2d(8)\n",
    "batch2 = torch.nn.BatchNorm2d(16)\n",
    "\n",
    "a = batch2(convex1(maxp(batch1(convex(image)))))\n",
    "print(a.shape)\n",
    "\n",
    "convtrans = torch.nn.ConvTranspose2d(16,8,kernel_size=2, stride=1)\n",
    "convtrans1 = torch.nn.ConvTranspose2d(8,3,kernel_size=1, stride=1)\n",
    "\n",
    "b = convtrans1(convtrans(a))\n",
    "print(b.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
    "\n",
    "# SKIP Connection\n",
    "#print(image.shape)\n",
    "#image = image.view(32, 3, 120, 120)\n",
    "#print(image.shape)\n",
    "\n",
    "# UnetAE class definition\n",
    "\n",
    "class unetAE(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(unetAE, self).__init__()\n",
    "\n",
    "    self.linearf = nn.Sequential(\n",
    "      nn.Linear(36864, 7600),\n",
    "      nn.Linear(7600, 1600),\n",
    "      nn.Linear(1600, 600),\n",
    "      nn.Linear(600, 256),\n",
    "      nn.Linear(256, 128)\n",
    "      )\n",
    "\n",
    "    self.linearb = nn.Sequential(\n",
    "      nn.Linear(128,256),\n",
    "      nn.Linear(256,600),\n",
    "      nn.Linear(600,1600),\n",
    "      nn.Linear(1600, 7600),\n",
    "      nn.Linear(7600, 36864),\n",
    "      )\n",
    "\n",
    "    self.down_conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    self.down_conv2 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    self.down_conv3 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    self.down_conv4 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(128, 256, kernel_size=3),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    self.up_conv1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=2, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    self.up_conv2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=2, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    self.up_conv3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=2, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    self.up_conv4 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 3, kernel_size=2, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "  \n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    \n",
    "    print(x.shape, \"fuck\")\n",
    "    x = self.down_conv1(x)\n",
    "    x = self.down_conv2(x)\n",
    "    x = self.down_conv3(x)\n",
    "    x = self.down_conv4(x)\n",
    "    print(x.shape, 'shape')\n",
    "    x = x.view(x.size(0), -1)\n",
    "\n",
    "    print(x.shape, \"yes\")\n",
    "    out = self.linearf(x)\n",
    "\n",
    "    out = self.linearb(out)\n",
    "\n",
    "    print(out.shape, \"rebuild linear shape\")\n",
    "\n",
    "    out = out.view(32,256,12,12)\n",
    "\n",
    "    print(out.shape, \"rebuild linear shape 1\")\n",
    "    out = self.up_conv1(out)\n",
    "    print(out.shape, \"rebuild linear shape 1.5\")\n",
    "    out = self.up_conv2(out)\n",
    "    print(out.shape, \"rebuild linear shape 2\")\n",
    "    out = self.up_conv3(out)\n",
    "    print(out.shape, \"rebuild linear shape 3\")\n",
    "    out = self.up_conv4(out)\n",
    "    print(out.shape, \"rebuild linear shape 2\")\n",
    "\n",
    "    \n",
    "\n",
    "    return out\n",
    "\n",
    "model2 = unetAE()\n",
    "model2.to(device)\n",
    "\n",
    "image = image.to(device)\n",
    "print(type(image))\n",
    "\n",
    "#x = model2(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-5.1990e-01, -4.9520e-01, -4.7797e-01,  ..., -4.1141e-01,\n",
      "           -4.1569e-01, -4.1781e-01],\n",
      "          [-4.9703e-01, -4.9020e-01, -4.7984e-01,  ..., -4.0931e-01,\n",
      "           -4.0392e-01, -4.0931e-01],\n",
      "          [-4.9150e-01, -4.8480e-01, -4.7533e-01,  ..., -3.9984e-01,\n",
      "           -4.0000e-01, -4.0686e-01],\n",
      "          ...,\n",
      "          [ 2.8121e-01,  3.5588e-01,  3.3922e-01,  ...,  6.0997e-01,\n",
      "            7.2353e-01,  7.7925e-01],\n",
      "          [ 5.7170e-01,  5.8049e-01,  7.0467e-01,  ...,  7.0739e-01,\n",
      "            6.6039e-01,  6.8853e-01],\n",
      "          [ 4.3536e-01,  6.0627e-01,  5.8908e-01,  ...,  6.0608e-01,\n",
      "            5.0088e-01,  5.5843e-01]],\n",
      "\n",
      "         [[-1.2775e-01, -1.0696e-01, -9.3660e-02,  ..., -1.1405e-02,\n",
      "           -1.5686e-02, -1.7810e-02],\n",
      "          [-1.0595e-01, -1.0196e-01, -9.5523e-02,  ..., -9.3136e-03,\n",
      "           -3.9216e-03, -9.3141e-03],\n",
      "          [-1.0588e-01, -1.0049e-01, -8.3170e-02,  ...,  1.6332e-04,\n",
      "            0.0000e+00, -6.8628e-03],\n",
      "          ...,\n",
      "          [ 3.0131e-01,  3.9167e-01,  3.5392e-01,  ...,  6.0507e-01,\n",
      "            7.2941e-01,  7.8415e-01],\n",
      "          [ 5.8369e-01,  5.9431e-01,  7.1114e-01,  ...,  6.9954e-01,\n",
      "            6.6363e-01,  6.7529e-01],\n",
      "          [ 4.3085e-01,  5.9382e-01,  5.8908e-01,  ...,  6.0824e-01,\n",
      "            5.0382e-01,  5.5670e-01]],\n",
      "\n",
      "         [[ 3.3500e-01,  3.5578e-01,  3.6909e-01,  ...,  4.3565e-01,\n",
      "            4.3137e-01,  4.2925e-01],\n",
      "          [ 3.5680e-01,  3.6078e-01,  3.6722e-01,  ...,  4.3775e-01,\n",
      "            4.4314e-01,  4.3774e-01],\n",
      "          [ 3.5686e-01,  3.6225e-01,  3.7958e-01,  ...,  4.4722e-01,\n",
      "            4.4706e-01,  4.4020e-01],\n",
      "          ...,\n",
      "          [ 4.0180e-01,  4.4902e-01,  4.1078e-01,  ...,  6.1732e-01,\n",
      "            6.9951e-01,  7.3105e-01],\n",
      "          [ 5.8301e-01,  5.9618e-01,  6.8154e-01,  ...,  6.7307e-01,\n",
      "            6.4608e-01,  6.7533e-01],\n",
      "          [ 4.9173e-01,  5.9637e-01,  5.9379e-01,  ...,  6.1686e-01,\n",
      "            5.3657e-01,  5.9046e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.5647e-01, -9.2394e-02,  1.2933e-01,  ..., -5.4145e-01,\n",
      "           -3.8060e-01, -2.4167e-01],\n",
      "          [-3.6233e-01,  9.5835e-03, -3.1127e-03,  ..., -2.9423e-01,\n",
      "           -4.1613e-01, -4.7176e-01],\n",
      "          [-4.1497e-01,  9.7569e-02, -6.4849e-02,  ..., -3.3119e-01,\n",
      "           -3.7994e-01, -4.3807e-01],\n",
      "          ...,\n",
      "          [ 5.5799e-01,  5.8162e-01,  6.5868e-01,  ...,  5.2379e-01,\n",
      "            5.4253e-01,  6.1863e-01],\n",
      "          [ 4.8354e-01,  5.1158e-01,  5.8673e-01,  ...,  5.2366e-01,\n",
      "            4.2819e-01,  4.9833e-01],\n",
      "          [ 4.8256e-01,  4.6974e-01,  5.2573e-01,  ...,  5.1525e-01,\n",
      "            3.4803e-01,  5.6958e-01]],\n",
      "\n",
      "         [[-4.4078e-01, -7.6707e-02,  1.4502e-01,  ..., -5.2576e-01,\n",
      "           -3.6492e-01, -2.2598e-01],\n",
      "          [-3.4664e-01,  2.5270e-02,  1.2574e-02,  ..., -2.7854e-01,\n",
      "           -4.0044e-01, -4.5608e-01],\n",
      "          [-3.9929e-01,  1.1326e-01, -4.9163e-02,  ..., -3.1550e-01,\n",
      "           -3.6426e-01, -4.2239e-01],\n",
      "          ...,\n",
      "          [ 5.5799e-01,  5.8162e-01,  6.5868e-01,  ...,  5.2069e-01,\n",
      "            5.3942e-01,  6.1863e-01],\n",
      "          [ 4.8354e-01,  5.1158e-01,  5.8673e-01,  ...,  5.2366e-01,\n",
      "            4.2819e-01,  4.9833e-01],\n",
      "          [ 4.8256e-01,  4.6974e-01,  5.2573e-01,  ...,  5.1525e-01,\n",
      "            3.4803e-01,  5.6958e-01]],\n",
      "\n",
      "         [[-4.6431e-01, -1.0024e-01,  1.2149e-01,  ..., -5.6498e-01,\n",
      "           -4.0413e-01, -2.6520e-01],\n",
      "          [-3.7017e-01,  1.7402e-03, -1.0956e-02,  ..., -3.1776e-01,\n",
      "           -4.3966e-01, -4.9529e-01],\n",
      "          [-4.2281e-01,  8.9726e-02, -7.2692e-02,  ..., -3.5472e-01,\n",
      "           -4.0347e-01, -4.6160e-01],\n",
      "          ...,\n",
      "          [ 5.5799e-01,  5.8162e-01,  6.5868e-01,  ...,  5.4569e-01,\n",
      "            5.6442e-01,  6.2484e-01],\n",
      "          [ 4.8354e-01,  5.1158e-01,  5.8673e-01,  ...,  5.3935e-01,\n",
      "            4.4387e-01,  4.9833e-01],\n",
      "          [ 4.8256e-01,  4.6974e-01,  5.2573e-01,  ...,  5.2913e-01,\n",
      "            3.4927e-01,  5.6958e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.3468e-01, -6.2134e-01, -6.7532e-01,  ...,  2.3356e-01,\n",
      "            2.2745e-01,  2.2630e-01],\n",
      "          [-6.5314e-01, -7.1456e-01, -6.6832e-01,  ...,  2.2353e-01,\n",
      "            2.3010e-01,  2.3031e-01],\n",
      "          [-6.9145e-01, -6.6838e-01, -6.8802e-01,  ...,  2.2432e-01,\n",
      "            2.2590e-01,  2.2484e-01],\n",
      "          ...,\n",
      "          [-4.9042e-01, -1.0874e-01, -1.6013e-01,  ..., -1.0297e-01,\n",
      "            1.0705e-02, -2.1513e-02],\n",
      "          [-4.0801e-01, -2.3034e-01, -1.3779e-01,  ...,  5.2255e-02,\n",
      "           -1.0127e-01, -1.3317e-01],\n",
      "          [-3.0722e-01, -3.5685e-01, -2.3764e-01,  ..., -1.2581e-01,\n",
      "           -8.1992e-02, -1.4785e-01]],\n",
      "\n",
      "         [[-4.2358e-01, -5.3899e-01, -5.9689e-01,  ...,  2.3356e-01,\n",
      "            2.3812e-01,  2.3833e-01],\n",
      "          [-5.7361e-01, -5.8770e-01, -5.6106e-01,  ...,  2.3243e-01,\n",
      "            2.4578e-01,  2.3031e-01],\n",
      "          [-6.1465e-01, -5.7892e-01, -5.9425e-01,  ...,  2.4001e-01,\n",
      "            2.4240e-01,  2.4052e-01],\n",
      "          ...,\n",
      "          [-5.7163e-01, -2.3431e-01, -2.9248e-01,  ..., -2.1024e-02,\n",
      "            7.0999e-02,  7.6770e-02],\n",
      "          [-4.1597e-01, -2.3760e-01, -1.4816e-01,  ...,  1.2670e-01,\n",
      "           -2.2401e-02, -6.1256e-02],\n",
      "          [-3.8944e-01, -3.9943e-01, -2.9442e-01,  ...,  7.5825e-02,\n",
      "            6.6654e-02, -6.7691e-02]],\n",
      "\n",
      "         [[-3.8629e-01, -5.5641e-01, -5.8905e-01,  ...,  1.6717e-01,\n",
      "            1.6142e-01,  1.5388e-01],\n",
      "          [-5.6340e-01, -5.6936e-01, -5.5997e-01,  ...,  1.6650e-01,\n",
      "            1.5167e-01,  1.5188e-01],\n",
      "          [-5.8371e-01, -5.6560e-01, -5.8298e-01,  ...,  1.5373e-01,\n",
      "            1.6078e-01,  1.5425e-01],\n",
      "          ...,\n",
      "          [-6.4404e-01, -3.5041e-01, -3.9997e-01,  ...,  1.7456e-02,\n",
      "            7.8760e-02,  9.8094e-02],\n",
      "          [-5.2423e-01, -3.7873e-01, -2.7350e-01,  ...,  1.1546e-01,\n",
      "            8.0888e-03,  2.3515e-02],\n",
      "          [-4.8630e-01, -5.2657e-01, -4.2335e-01,  ...,  4.6490e-02,\n",
      "            7.5688e-02, -5.3789e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.0719e-01, -1.6209e-01, -1.5425e-01,  ..., -6.0131e-01,\n",
      "           -4.9412e-01, -4.6928e-01],\n",
      "          [-1.1765e-01, -1.0392e-01, -4.9020e-02,  ..., -5.7647e-01,\n",
      "           -5.1176e-01, -5.6275e-01],\n",
      "          [-9.0196e-02, -7.4510e-02, -9.0196e-02,  ..., -4.4314e-01,\n",
      "           -5.5556e-01, -5.4183e-01],\n",
      "          ...,\n",
      "          [-5.3072e-01, -5.5948e-01, -5.6994e-01,  ..., -9.3987e-01,\n",
      "           -4.0850e-01, -2.6078e-01],\n",
      "          [-5.4510e-01, -5.6275e-01, -5.9412e-01,  ..., -9.5882e-01,\n",
      "           -3.1569e-01, -3.1373e-01],\n",
      "          [-4.4314e-01, -6.3921e-01, -6.3660e-01,  ..., -9.5033e-01,\n",
      "           -3.1830e-01, -2.2614e-01]],\n",
      "\n",
      "         [[-2.6797e-02,  3.9216e-03,  3.0719e-02,  ..., -3.9869e-01,\n",
      "           -3.8235e-01, -4.0131e-01],\n",
      "          [ 1.9608e-02,  5.0980e-02,  4.1177e-02,  ..., -3.9216e-01,\n",
      "           -4.0196e-01, -3.8431e-01],\n",
      "          [ 2.7451e-02,  7.2549e-02,  6.6013e-02,  ..., -3.6405e-01,\n",
      "           -3.5948e-01, -3.7647e-01],\n",
      "          ...,\n",
      "          [-5.0850e-01, -6.8170e-01, -7.1372e-01,  ..., -9.4052e-01,\n",
      "           -1.9673e-01, -2.1634e-01],\n",
      "          [-5.4118e-01, -6.8824e-01, -6.9020e-01,  ..., -9.5686e-01,\n",
      "           -2.0196e-01, -1.9608e-01],\n",
      "          [-5.3333e-01, -6.7451e-01, -7.3268e-01,  ..., -9.4444e-01,\n",
      "           -2.0000e-01, -2.7386e-01]],\n",
      "\n",
      "         [[-2.4706e-01, -2.0654e-01, -1.8627e-01,  ..., -7.4118e-01,\n",
      "           -7.1176e-01, -8.0261e-01],\n",
      "          [-1.7451e-01, -1.3725e-01, -1.7059e-01,  ..., -6.3333e-01,\n",
      "           -7.4902e-01, -6.7647e-01],\n",
      "          [-2.4641e-01, -1.2418e-01, -1.9935e-01,  ..., -8.0523e-01,\n",
      "           -6.7451e-01, -7.0523e-01],\n",
      "          ...,\n",
      "          [-6.9608e-01, -7.0915e-01, -7.9216e-01,  ..., -9.5621e-01,\n",
      "           -1.6340e-01, -1.7386e-01],\n",
      "          [-5.8627e-01, -8.2353e-01, -7.9412e-01,  ..., -9.6275e-01,\n",
      "           -1.8824e-01, -1.5294e-01],\n",
      "          [-5.8889e-01, -7.8693e-01, -7.6471e-01,  ..., -9.6340e-01,\n",
      "           -1.4052e-01, -1.5621e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.6144e-01,  7.8431e-03,  3.0065e-02,  ...,  2.6797e-02,\n",
      "           -3.1373e-02, -1.0261e-01],\n",
      "          [-2.9346e-01, -1.0000e-01,  9.8693e-02,  ...,  6.9280e-02,\n",
      "           -5.8823e-03, -2.4182e-02],\n",
      "          [-2.5359e-01, -1.3333e-01,  2.1176e-01,  ...,  9.4118e-02,\n",
      "            4.3137e-02,  5.0326e-02],\n",
      "          ...,\n",
      "          [-6.2157e-01, -8.4314e-01, -8.4314e-01,  ..., -5.9412e-01,\n",
      "           -6.9804e-01, -6.3203e-01],\n",
      "          [-7.0131e-01, -7.8627e-01, -6.9673e-01,  ..., -5.7124e-01,\n",
      "           -6.4510e-01, -5.9935e-01],\n",
      "          [-7.0458e-01, -7.6078e-01, -8.6144e-01,  ..., -2.9216e-01,\n",
      "           -6.0196e-01, -6.1372e-01]],\n",
      "\n",
      "         [[-3.9216e-01, -1.0196e-01, -5.6209e-02,  ..., -4.5098e-02,\n",
      "           -1.3725e-01, -1.6274e-01],\n",
      "          [-3.9935e-01, -1.8431e-01, -3.2680e-03,  ...,  1.3071e-02,\n",
      "           -7.0588e-02, -1.0392e-01],\n",
      "          [-3.9542e-01, -2.3922e-01,  1.1961e-01,  ...,  3.9216e-02,\n",
      "           -1.7647e-02, -4.5760e-03],\n",
      "          ...,\n",
      "          [-6.1830e-01, -8.6863e-01, -8.8235e-01,  ..., -7.0915e-01,\n",
      "           -7.6863e-01, -7.2092e-01],\n",
      "          [-6.6340e-01, -7.9412e-01, -7.3595e-01,  ..., -6.6471e-01,\n",
      "           -7.3922e-01, -6.9478e-01],\n",
      "          [-6.4771e-01, -7.9020e-01, -9.0980e-01,  ..., -3.9216e-01,\n",
      "           -7.1373e-01, -6.8235e-01]],\n",
      "\n",
      "         [[-3.9608e-01, -1.1765e-01, -8.6275e-02,  ..., -1.6928e-01,\n",
      "           -2.0392e-01, -2.4444e-01],\n",
      "          [-3.6667e-01, -2.1176e-01, -6.3399e-02,  ..., -1.2810e-01,\n",
      "           -1.5294e-01, -1.7582e-01],\n",
      "          [-4.0065e-01, -2.9804e-01,  5.3595e-02,  ..., -1.0196e-01,\n",
      "           -1.0588e-01, -1.4967e-01],\n",
      "          ...,\n",
      "          [-6.3464e-01, -8.4314e-01, -8.2745e-01,  ..., -7.4444e-01,\n",
      "           -7.7451e-01, -7.4575e-01],\n",
      "          [-7.6405e-01, -7.9608e-01, -6.8431e-01,  ..., -6.5556e-01,\n",
      "           -6.9804e-01, -7.3465e-01],\n",
      "          [-7.5425e-01, -7.8627e-01, -8.2941e-01,  ..., -4.5490e-01,\n",
      "           -7.1961e-01, -6.9150e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.9173e-01, -7.0373e-02, -7.2059e-02,  ..., -3.1902e-01,\n",
      "           -2.9794e-01, -2.1371e-01],\n",
      "          [-2.7961e-02,  2.9628e-02, -3.7255e-03,  ...,  6.8392e-01,\n",
      "           -3.6808e-01, -1.3971e-01],\n",
      "          [-1.0265e-01, -4.2549e-02, -3.6275e-02,  ...,  7.1029e-01,\n",
      "            7.3265e-01,  3.9206e-01],\n",
      "          ...,\n",
      "          [-3.3794e-01, -4.3127e-01, -4.5441e-01,  ..., -6.7255e-01,\n",
      "           -6.6078e-01, -6.6392e-01],\n",
      "          [-3.0929e-01, -4.1825e-01, -5.5833e-01,  ..., -6.1892e-01,\n",
      "           -5.7669e-01, -5.9098e-01],\n",
      "          [-4.0233e-01, -5.4274e-01, -5.6647e-01,  ..., -6.5216e-01,\n",
      "           -5.9457e-01, -5.7492e-01]],\n",
      "\n",
      "         [[-8.0467e-01, -7.8875e-01, -8.1549e-01,  ..., -8.1069e-01,\n",
      "           -7.8606e-01, -7.8116e-01],\n",
      "          [-7.7037e-01, -7.8039e-01, -8.0775e-01,  ...,  6.8775e-01,\n",
      "           -7.4133e-01, -7.6937e-01],\n",
      "          [-7.8755e-01, -7.6824e-01, -7.7108e-01,  ...,  6.6422e-01,\n",
      "            6.8647e-01,  3.6490e-01],\n",
      "          ...,\n",
      "          [-7.6069e-01, -7.7971e-01, -7.7255e-01,  ..., -8.2157e-01,\n",
      "           -8.4059e-01, -8.4039e-01],\n",
      "          [-7.7563e-01, -7.8270e-01, -8.1559e-01,  ..., -8.1265e-01,\n",
      "           -7.9978e-01, -8.3647e-01],\n",
      "          [-7.6349e-01, -7.8902e-01, -8.0765e-01,  ..., -8.2471e-01,\n",
      "           -8.2437e-01, -8.1806e-01]],\n",
      "\n",
      "         [[-8.2075e-01, -7.9725e-01, -8.2637e-01,  ..., -6.7725e-01,\n",
      "           -8.0449e-01, -7.5018e-01],\n",
      "          [-7.7227e-01, -7.7725e-01, -7.9000e-01,  ...,  7.6863e-01,\n",
      "           -5.6525e-01, -7.5151e-01],\n",
      "          [-7.5667e-01, -7.5657e-01, -7.6324e-01,  ...,  7.0196e-01,\n",
      "            7.2657e-01,  5.3921e-01],\n",
      "          ...,\n",
      "          [-7.1549e-01, -7.3510e-01, -7.1863e-01,  ..., -7.7451e-01,\n",
      "           -7.7814e-01, -7.9529e-01],\n",
      "          [-6.8504e-01, -7.0727e-01, -7.6324e-01,  ..., -7.7559e-01,\n",
      "           -7.6057e-01, -7.9490e-01],\n",
      "          [-7.4704e-01, -7.7961e-01, -7.5667e-01,  ..., -8.0118e-01,\n",
      "           -7.9182e-01, -7.7884e-01]]]])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import os\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = trans\n",
    "        self.image_filenames = os.listdir(root_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = os.path.join(self.root_dir, self.image_filenames[index])\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "dataset = CustomDataset('D:/tempmassstorage/train2014/train2014')\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "a = iter(dataloader)\n",
    "b = next(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 120, 120]) fuck\n",
      "torch.Size([32, 256, 12, 12]) shape\n",
      "torch.Size([32, 36864]) yes\n",
      "torch.Size([32, 36864]) rebuild linear shape\n",
      "torch.Size([32, 256, 12, 12]) rebuild linear shape 1\n",
      "torch.Size([32, 128, 24, 24]) rebuild linear shape 1.5\n",
      "torch.Size([32, 64, 48, 48]) rebuild linear shape 2\n",
      "torch.Size([32, 32, 96, 96]) rebuild linear shape 3\n",
      "torch.Size([32, 3, 192, 192]) rebuild linear shape 2\n",
      "torch.Size([32, 3, 192, 192])  generated\n",
      "torch.Size([32, 3, 120, 120])  image\n",
      "<built-in method type of Tensor object at 0x00000222F231D300>  generated\n",
      "<built-in method type of Tensor object at 0x000002219CD407C0>  image\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\deshp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([32, 3, 120, 120])) that is different to the input size (torch.Size([32, 3, 192, 192])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (192) must match the size of tensor b (120) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\deshp\\Desktop\\😈\\src\\microservice\\pytorch\\testing_notebooks\\unet.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/deshp/Desktop/%F0%9F%98%88/src/microservice/pytorch/testing_notebooks/unet.ipynb#W4sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mprint\u001b[39m(generated\u001b[39m.\u001b[39mtype, \u001b[39m\"\u001b[39m\u001b[39m generated\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/deshp/Desktop/%F0%9F%98%88/src/microservice/pytorch/testing_notebooks/unet.ipynb#W4sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mprint\u001b[39m(image\u001b[39m.\u001b[39mtype, \u001b[39m\"\u001b[39m\u001b[39m image\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/deshp/Desktop/%F0%9F%98%88/src/microservice/pytorch/testing_notebooks/unet.ipynb#W4sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m loss \u001b[39m=\u001b[39m lossfn(generated, image)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/deshp/Desktop/%F0%9F%98%88/src/microservice/pytorch/testing_notebooks/unet.ipynb#W4sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/deshp/Desktop/%F0%9F%98%88/src/microservice/pytorch/testing_notebooks/unet.ipynb#W4sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mloss: \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m.\u001b[39mitem()\u001b[39m}\u001b[39;00m\u001b[39m, epoch: \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\deshp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\deshp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 536\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mmse_loss(\u001b[39minput\u001b[39;49m, target, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction)\n",
      "File \u001b[1;32mc:\\Users\\deshp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:3294\u001b[0m, in \u001b[0;36mmse_loss\u001b[1;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3291\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   3292\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3294\u001b[0m expanded_input, expanded_target \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mbroadcast_tensors(\u001b[39minput\u001b[39;49m, target)\n\u001b[0;32m   3295\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_nn\u001b[39m.\u001b[39mmse_loss(expanded_input, expanded_target, _Reduction\u001b[39m.\u001b[39mget_enum(reduction))\n",
      "File \u001b[1;32mc:\\Users\\deshp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\functional.py:74\u001b[0m, in \u001b[0;36mbroadcast_tensors\u001b[1;34m(*tensors)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function(tensors):\n\u001b[0;32m     73\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, \u001b[39m*\u001b[39mtensors)\n\u001b[1;32m---> 74\u001b[0m \u001b[39mreturn\u001b[39;00m _VF\u001b[39m.\u001b[39;49mbroadcast_tensors(tensors)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (192) must match the size of tensor b (120) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "# hyper parameters for training\n",
    "model =unetAE()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.05)\n",
    "lossfn = torch.nn.MSELoss()\n",
    "epoch = 100\n",
    "\n",
    "test = torch.nn.KLDivLoss()\n",
    "\n",
    "for i in range(1):\n",
    "    for image in dataloader:\n",
    "        generated = model(image)\n",
    "\n",
    "        print(generated.shape, \" generated\")\n",
    "        print(image.shape, \" image\")\n",
    "\n",
    "        print(generated.type, \" generated\")\n",
    "        print(image.type, \" image\")\n",
    "\n",
    "        loss = lossfn(generated, image)\n",
    "\n",
    "        loss.backward()\n",
    "        print(f'loss: {loss.item()}, epoch: {i}')\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4673])\n"
     ]
    }
   ],
   "source": [
    "# scheduler\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def linear_beta_scheduler(timestamps=None, start=0.0001, end=0.02):\n",
    "    return torch.linspace(start, end, timestamps)\n",
    "\n",
    "#print(torch.linspace(0.00001, 0.02, 100))\n",
    "a = torch.tensor([0.01])\n",
    "print(torch.rand_like(a))\n",
    "\n",
    "alpha = 1 - (linear_beta_scheduler(Time=10))\n",
    "\n",
    "alpha_cum_prod = torch.prod(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\deshp\\Desktop\\😈\\src\\microservice\\pytorch\\testing_notebooks\\unet.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/deshp/Desktop/%F0%9F%98%88/src/microservice/pytorch/testing_notebooks/unet.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(x\u001b[39m.\u001b[39mshape)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/deshp/Desktop/%F0%9F%98%88/src/microservice/pytorch/testing_notebooks/unet.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mview(\u001b[39m3\u001b[39m,\u001b[39m240\u001b[39m,\u001b[39m240\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/deshp/Desktop/%F0%9F%98%88/src/microservice/pytorch/testing_notebooks/unet.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m image \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39mToPILImage()(x)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "\n",
    "x = x.view(3,240,240)\n",
    "\n",
    "image = transforms.ToPILImage()(x)\n",
    "image.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
